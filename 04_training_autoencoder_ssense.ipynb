{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder on SSENSE Dataset\n",
    "\n",
    "The purpose is to find similar products within the dataset based on the image similarities.\n",
    "\n",
    "**Dataset:**\n",
    "SSENSE dataset is consist of images of 224x224 pixels.<br>\n",
    "Using Autoencoder, we are going to reconstruct images based on a trained model. In this case, these reconstructed images have less detailed-features, and they mostly represent eigen-features of their representative image. Since these images are dimensionally reduced, it would be much faster to compute the similarity/distance based on the reconstructed images instead of the original images.\n",
    "\n",
    "* 1. A convolutional autoencoder has been designed to create a reconstructed images which are representative of image within the dataset.\n",
    "* 2. Eigenfeature representative would be generated for all images in Test set.\n",
    "* 3. One sample image is selected from Test set.\n",
    "* 4. The eigenfeature output of the selected image would be compared with all eigenfeatures of all images, and their distance would be calculated.\n",
    "* 5. Those products whose eigenfeatures are closest to the queried eigenfeature, are selected as the similar products.\n",
    "\n",
    "### Libraries:\n",
    "**Keras:** To build the model of convolutional autoencoder.<br>\n",
    "**Matplotlib:** To plot the model performance and showing the images of eigenfeatures and actual images.<br>\n",
    "**sklearn:** Using the KNN to find the nearest products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-c2864f59bb08>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mConv2D\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMaxPooling2D\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mUpSampling2D\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Loading Dataset\n",
    "Numpy dataset is being loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-9c2b0244cac7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mmypath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"C:\\\\Users\\\\kaveh.bakhtiyari\\\\JupyterProjects\\\\ImageSearch-ACE\\\\data\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mdataset_file\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmypath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"\\\\dataset_data.npy\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mtotal_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfix_imports\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Dataset loaded.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time.time()\n",
    "\n",
    "# loading numpy dataset\n",
    "mypath = \".\\\\data\"\n",
    "dataset_file = os.path.dirname(mypath) + \"\\\\dataset_data.npy\"\n",
    "total_data = np.load(dataset_file, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "print(\"Dataset loaded.\")\n",
    "print(\"{:.2f} seconds passed.\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Dataset Splitting\n",
    "Loaded dataset is being splitted into a train set and a test set.<br>\n",
    "The splitted datasets are being normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting train and test sets...\n",
      "Split completed.\n",
      "Train set:  (12231, 224, 224, 1)  - 67.00%\n",
      "Test set:  (6025, 224, 224, 1)  - 33.00%\n",
      "Type converting...\n",
      "Type conversion completed.\n",
      "98.77 seconds passed.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "total_samples = len(total_data) #18256\n",
    "print(\"Spliting train and test sets...\")\n",
    "# dataset splitting\n",
    "x_train, x_test, _, _ = train_test_split(total_data, total_data, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Split completed.\")\n",
    "\n",
    "# reporting a summary of split\n",
    "print(\"Train set: \", x_train.shape, \" - {:.2f}%\".format((x_train.shape[0] * 100)/total_samples))\n",
    "print(\"Test set: \", x_test.shape, \" - {:.2f}%\".format((x_test.shape[0] * 100)/total_samples))\n",
    "\n",
    "print (\"Normalizing...\")\n",
    "# normalizing\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print (\"Normalization completed.\")\n",
    "print(\"{:.2f} seconds passed.\".format(time.time() - t0))\n",
    "#x_train = np.reshape(x_train, (len(x_train), 224, 224, 1))  # adapt this if using `channels_first` image data format\n",
    "#x_test = np.reshape(x_test, (len(x_test), 224, 224, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Convolutional Autoencoder\n",
    "Designing a convolutional autoencoder to build image representatives.<br>\n",
    "Later the **SSENSE** dataset is loaded from Keras for training.<br>\n",
    "The generated model would be saved at the end for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 16)      4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 224, 224, 1)       145       \n",
      "=================================================================\n",
      "Total params: 277,345\n",
      "Trainable params: 277,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-4482344d0dfc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;31m# training the dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m autoencoder.fit(x_train, x_train,\n\u001B[0m\u001B[0;32m     47\u001B[0m                \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m                \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(224, 224, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) #224 x 224 x 16\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) #112 x 112 x 16\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #112 x 112 x 32\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) #56 x 56 x 32\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #56 x 56 x 32\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) #28 x 28 x 32\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) #28 x 28 x 64\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) #14 x 14 x 64\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) #14 x 14 x 64\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) #7 x 7 x 64\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) #7 x 7 x 64\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)  #4 x 4 x 64\n",
    "\n",
    "# at this point the representation is (4, 4, 64) i.e. 1024-dimensional\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded) #4 x 4 x 64\n",
    "x = UpSampling2D((2, 2))(x) #8 x 8 x 64\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) #8 x 8 x 64\n",
    "x = UpSampling2D((2, 2))(x) #16 x 16 x 64\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x) #14 x 14 x 64\n",
    "x = UpSampling2D((2, 2))(x) #28 x 28 x 64\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) #28 x 28 x 64\n",
    "x = UpSampling2D((2, 2))(x) #56 x 56 x 64\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #56 x 56 x 32\n",
    "x = UpSampling2D((2, 2))(x) #112 x 112 x 32\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x) #112 x 112 x 16\n",
    "x = UpSampling2D((2, 2))(x) #224 x 224 x 16\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy') #adadelta\n",
    "\n",
    "# printing model architecture\n",
    "print(autoencoder.summary())\n",
    "\n",
    "from keras.callbacks import History\n",
    "history = History()\n",
    "\n",
    "# training the dataset\n",
    "autoencoder.fit(x_train, x_train,\n",
    "               epochs=10,\n",
    "               batch_size=128,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test, x_test), callbacks=[history])\n",
    "\n",
    "# storing the model\n",
    "autoencoder.save('C:\\\\Users\\\\kaveh.bakhtiyari\\\\JupyterProjects\\\\ImageSearch-ACE\\\\Models\\\\autoen_ssense.h5')\n",
    "#del autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Performance\n",
    "The performance of the model based on the **Loss** and **Val_Loss** is ploted.<br>\n",
    "The model was tested based on the various types of neutwork, by extending the network (going deeper), but the performance did not change significantly.\n",
    "\n",
    "In our tests, we had 200 epochs. There was a huge loss spike on 100 epochs, but the network recovered quickly.<br>\n",
    "150 epochs recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "for index, key in enumerate(history.history.keys()):\n",
    "    print(key, history.history[key])\n",
    "    plt.plot(history.history[key], label=key)\n",
    "\n",
    "plt.ylabel(key)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Reconstructing & Sample Checking\n",
    "\n",
    "All images within the test set would be reconstructed by autoencoder model.<br>\n",
    "Then a sample of 10 images are ploted along with the originals and reconstructed-images to check how the model worked visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model (if required)\n",
    "from keras.models import load_model\n",
    "autoencoder = load_model('.\\\\models\\\\autoen_ssense.h5')\n",
    "\n",
    "# Generating the eigen-features (reconstructed images) for all images within test set\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "# Plotting n sample of images/eigen-features from test set\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    i = i + 1\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(224, 224))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(224, 224))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Query (Nearest Neighbors)\n",
    "\n",
    "At this stage, decoded images are reshaped to a linear array for calculating the distance.<br>\n",
    "Then, a sample image from **Test Set** is selected, and its similarity distance is calculated against all the reconstructed images in the dataset.<br>\n",
    "The closest items (*n_neighbors*) are extracted to be ploted as the most *n* similar products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-9b9d032f6ccb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Fit the NN algorithm to the encoded test set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mx_t\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoded_imgs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m50176\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoded_imgs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mx_t\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecoded_imgs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50176\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the NN algorithm to the encoded test set\n",
    "x_t = np.zeros((len(decoded_imgs),50176))\n",
    "for i in range(len(decoded_imgs)):\n",
    "    x_t[i] = decoded_imgs[i].reshape(50176)\n",
    "\n",
    "# fiting to find the nearest neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=20).fit(x_t)\n",
    "\n",
    "# selecting a sample product\n",
    "sample_image = 200\n",
    "query_image = np.zeros((1,50176))\n",
    "query_image[0] = np.array(decoded_imgs[sample_image].reshape(50176))\n",
    "#np.array(query_code)\n",
    "\n",
    "#print (query_image.shape)\n",
    "# finding the closest images to the encoded query image\n",
    "distances, indices = nbrs.kneighbors(query_image)\n",
    "\n",
    "print(\"Distances:\", distances)\n",
    "print(\"Indices:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Visualization\n",
    "\n",
    "When the similar eigen-features are found, the actual product of those features are ploted.<br>\n",
    "In this section, the followings are ploted:\n",
    "* Original Image: The original queried image,\n",
    "* Queried Image: The eigen-feature image of the queried image,\n",
    "* Original Images of similar products to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the original image\n",
    "plt.figure(figsize=(5, 2))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.subplots_adjust(bottom=0.1, top=1)\n",
    "plt.imshow(x_test[sample_image].reshape(224, 224))\n",
    "plt.xlabel(\"Original Image\")\n",
    "\n",
    "# Plotting the constructed image of the original image\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(decoded_imgs[sample_image].reshape(224, 224))\n",
    "plt.gray()\n",
    "plt.xlabel(\"Queried Image\")\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the n origianl images which are found to be the nearest within the test-set\n",
    "n = 40\n",
    "plt.figure(figsize=(40, 8))\n",
    "j = 0\n",
    "for index, value in enumerate(indices[0]):\n",
    "    # display original from test set\n",
    "    j = j + 1\n",
    "    ax = plt.subplot(int(n/10), 10, j)\n",
    "    plt.subplots_adjust(bottom=0.1, top=1)\n",
    "    plt.imshow(x_test[value].reshape(224, 224))\n",
    "    plt.gray()\n",
    "    plt.xlabel(value)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    j = j + 1\n",
    "    # display reconstructed\n",
    "    ax = plt.subplot(int(n/10), 10, j)\n",
    "    plt.imshow(decoded_imgs[value].reshape(224, 224))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
